# num_epochs = 5
# num_classes = 5
# # Training and validation loop
# train_class_accuracy = ClassBasedAccuracy(num_classes=num_classes)
# val_class_accuracy = ClassBasedAccuracy(num_classes=num_classes)

# tensorboard_logger = TensorBoardLogger(log_dir='tensorboard_logs')
# for epoch in range(num_epochs):
#     # Training phase
#     model.train()
#     train_class_accuracy.reset()
#     running_loss = 0.0
#     total_correct = 0
#     total_samples = 0

#     progress_bar = tqdm(train_loader, 
#                          desc=f"Epoch: {epoch + 1}/{num_epochs}", 
#                          leave=False, 
#                          ncols=120)

#     for i, (inputs, labels) in enumerate(progress_bar):
#         inputs, labels = inputs.to(device), labels.to(device)
        
#         # Zero the parameter gradients
#         optimizer.zero_grad()
        
#         # Forward pass
#         outputs = model(inputs)
#         loss = custom_loss_fn(outputs, labels)
        
#         # Backward pass and optimize
#         loss.backward()
#         optimizer.step()
        
#         # Predictions
#         _, predicted = torch.max(outputs, 1)
        
#         # Update training metrics
#         train_class_accuracy.update_state(labels, predicted)
#         running_loss += loss.item()
#         total_correct += (predicted == labels).sum().item()
#         total_samples += labels.size(0)

#         # Update progress bar
#         progress_bar.set_postfix(
#             batch=f"[{i + 1}/{len(train_loader)}]", 
#             loss=f"{loss.item():.4f}", 
#             overall_acc=f"{100.0 * total_correct / total_samples:.2f}%"
#         )

#     # Compute training metrics for the epoch
#     train_class_acc = train_class_accuracy.compute()
#     train_overall_acc = 100.0 * total_correct / total_samples
#     train_avg_class_acc = train_class_acc.mean().item()

#     tensorboard_logger.log_epoch(
#         epoch,
#         per_class_acc=train_class_acc.cpu().numpy(),  # Per class accuracies
#         per_class_loss=[running_loss / len(train_loader)],  # Average loss per class
#         overall_acc=train_overall_acc
#     )

#     # Validation phase
#     model.eval()
#     val_class_accuracy.reset()
#     val_running_loss = 0.0
#     val_total_correct = 0
#     val_total_samples = 0

#     with torch.no_grad():
#         for inputs, labels in tqdm(val_loader, desc="Validation", leave=False):
#             inputs, labels = inputs.to(device), labels.to(device)
            
#             # Forward pass
#             outputs = model(inputs)
#             loss = custom_loss_fn(outputs, labels)
            
#             # Predictions
#             _, predicted = torch.max(outputs, 1)
            
#             # Update validation metrics
#             val_class_accuracy.update_state(labels, predicted)
#             val_running_loss += loss.item()
#             val_total_correct += (predicted == labels).sum().item()
#             val_total_samples += labels.size(0)

#     # Compute validation metrics
#     val_class_acc = val_class_accuracy.compute()
#     val_overall_acc = 100.0 * val_total_correct / val_total_samples
#     val_avg_class_acc = val_class_acc.mean().item()

#     tensorboard_logger.log_epoch(
#         epoch,
#         per_class_acc=val_class_acc.cpu().numpy(),
#         per_class_loss=[val_running_loss / len(val_loader)],
#         overall_acc=val_overall_acc
#     )
#     # Print epoch summary
#     print(f"\nEpoch {epoch + 1}/{num_epochs}")
#     print(f"Training   - Overall Accuracy: {train_overall_acc:.2f}%")
#     print(f"Training   - Per Class Accuracies: {train_class_acc.cpu().numpy()}")
#     print(f"Training   - Avg Class Accuracy: {train_avg_class_acc*100:.2f}%")
#     print(f"Validation - Overall Accuracy: {val_overall_acc:.2f}%")
#     print(f"Validation - Per Class Accuracies: {val_class_acc.cpu().numpy()}")
#     print(f"Validation - Avg Class Accuracy: {val_avg_class_acc*100:.2f}%")


# tensorboard_logger.close()



# def train_and_validate_epoch(
#     model, 
#     train_loader, 
#     val_loader, 
#     optimizer, 
#     custom_loss_fn, 
#     device, 
#     num_classes, 
#     epoch, 
#     num_epochs, 
#     tensorboard_logger=None
# ):
#     # Training phase
#     train_class_accuracy = ClassBasedAccuracy(num_classes=num_classes)
#     model.train()
#     train_class_accuracy.reset()
#     running_loss = 0.0
#     total_correct = 0
#     total_samples = 0

#     progress_bar = tqdm(train_loader, 
#                          desc=f"Epoch: {epoch + 1}/{num_epochs}", 
#                          leave=False, 
#                          ncols=120)

#     for i, (inputs, labels) in enumerate(progress_bar):
#         inputs, labels = inputs.to(device), labels.to(device)
        
#         optimizer.zero_grad()
#         outputs = model(inputs)
#         loss = custom_loss_fn(outputs, labels)
        
#         loss.backward()
#         optimizer.step()
        
#         _, predicted = torch.max(outputs, 1)
        
#         train_class_accuracy.update_state(labels, predicted)
#         running_loss += loss.item()
#         total_correct += (predicted == labels).sum().item()
#         total_samples += labels.size(0)

#         progress_bar.set_postfix(
#             batch=f"[{i + 1}/{len(train_loader)}]", 
#             loss=f"{loss.item():.4f}", 
#             overall_acc=f"{100.0 * total_correct / total_samples:.2f}%"
#         )

#     # Training metrics
#     train_class_acc = train_class_accuracy.compute()
#     train_overall_acc = 100.0 * total_correct / total_samples
#     train_avg_class_acc = train_class_acc.mean().item()

#     if tensorboard_logger:
#         tensorboard_logger.log_epoch(
#             epoch,
#             per_class_acc=train_class_acc.cpu().numpy(),
#             per_class_loss=[running_loss / len(train_loader)],
#             overall_acc=train_overall_acc
#         )

#     # Validation phase
#     val_class_accuracy = ClassBasedAccuracy(num_classes=num_classes)
#     model.eval()
#     val_class_accuracy.reset()
#     val_running_loss = 0.0
#     val_total_correct = 0
#     val_total_samples = 0

#     with torch.no_grad():
#         for inputs, labels in tqdm(val_loader, desc="Validation", leave=False):
#             inputs, labels = inputs.to(device), labels.to(device)
            
#             outputs = model(inputs)
#             loss = custom_loss_fn(outputs, labels)
            
#             _, predicted = torch.max(outputs, 1)
            
#             val_class_accuracy.update_state(labels, predicted)
#             val_running_loss += loss.item()
#             val_total_correct += (predicted == labels).sum().item()
#             val_total_samples += labels.size(0)

#     # Validation metrics
#     val_class_acc = val_class_accuracy.compute()
#     val_overall_acc = 100.0 * val_total_correct / val_total_samples
#     val_avg_class_acc = val_class_acc.mean().item()

#     if tensorboard_logger:
#         tensorboard_logger.log_epoch(
#             epoch,
#             per_class_acc=val_class_acc.cpu().numpy(),
#             per_class_loss=[val_running_loss / len(val_loader)],
#             overall_acc=val_overall_acc
#         )

#     # Print epoch summary
#     print(f"\nEpoch {epoch + 1}/{num_epochs}")
#     print(f"Training   - Overall Accuracy: {train_overall_acc:.2f}%")
#     print(f"Training   - Per Class Accuracies: {train_class_acc.cpu().numpy()}")
#     # print(f"Training   - Avg Class Accuracy: {train_avg_class_acc*100:.2f}%")
#     print(f"Validation - Overall Accuracy: {val_overall_acc:.2f}%")
#     print(f"Validation - Per Class Accuracies: {val_class_acc.cpu().numpy():.4f}")
#     # print(f"Validation - Avg Class Accuracy: {val_avg_class_acc*100:.2f}%")

#     return model







def train_and_validate_epoch(
    model, 
    train_loader, 
    val_loader, 
    optimizer, 
    custom_loss_fn, 
    device, 
    num_classes, 
    epoch, 
    num_epochs,
    lookup
):
    # Training phase
    train_class_accuracy = ClassBasedAccuracy(num_classes=num_classes)
    model.train()
    train_class_accuracy.reset()
    running_loss = 0.0
    total_correct = 0
    total_samples = 0

    progress_bar = tqdm(train_loader, 
                         desc=f"Epoch: {epoch + 1}/{num_epochs}", 
                         leave=False, 
                         ncols=120)

    for i, (inputs, labels) in enumerate(progress_bar):
        inputs, labels = inputs.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = custom_loss_fn(outputs, labels)
        
        loss.backward()
        optimizer.step()
        
        _, predicted = torch.max(outputs, 1)
        
        train_class_accuracy.update_state(labels, predicted)
        running_loss += loss.item()
        total_correct += (predicted == labels).sum().item()
        total_samples += labels.size(0)

        progress_bar.set_postfix(
            batch=f"[{i + 1}/{len(train_loader)}]", 
            loss=f"{loss.item():.4f}", 
            overall_acc=f"{100.0 * total_correct / total_samples:.2f}%"
        )

    # Training metrics
    train_class_acc = train_class_accuracy.compute()
    train_overall_acc = 100.0 * total_correct / total_samples
    train_avg_class_acc = train_class_acc.mean().item()

    # Log training metrics to wandb
    train_class_acc_table = wandb.Table(columns=["Class Name", "Accuracy"])
    for i, acc in enumerate(train_class_acc.cpu().numpy()):
        train_class_acc_table.add_data(lookup[i], acc)

    wandb.log({
        "train/loss": running_loss / len(train_loader),
        "train/overall_accuracy": train_overall_acc,
        "train/per_class_accuracies": train_class_acc_table
    })

    # Validation phase
    val_class_accuracy = ClassBasedAccuracy(num_classes=num_classes)
    model.eval()
    val_class_accuracy.reset()
    val_running_loss = 0.0
    val_total_correct = 0
    val_total_samples = 0

    with torch.no_grad():
        for inputs, labels in tqdm(val_loader, desc="Validation", leave=False):
            inputs, labels = inputs.to(device), labels.to(device)
            
            outputs = model(inputs)
            loss = custom_loss_fn(outputs, labels)
            
            _, predicted = torch.max(outputs, 1)
            
            val_class_accuracy.update_state(labels, predicted)
            val_running_loss += loss.item()
            val_total_correct += (predicted == labels).sum().item()
            val_total_samples += labels.size(0)

    # Validation metrics
    val_class_acc = val_class_accuracy.compute()
    val_overall_acc = 100.0 * val_total_correct / val_total_samples
    val_avg_class_acc = val_class_acc.mean().item()

    # Log validation metrics to wandb
    val_class_acc_table = wandb.Table(columns=["Class Name", "Accuracy"])
    for i, acc in enumerate(val_class_acc.cpu().numpy()):
        val_class_acc_table.add_data(lookup[i], acc)

    wandb.log({
        "val/loss": val_running_loss / len(val_loader),
        "val/overall_accuracy": val_overall_acc,
        "val/per_class_accuracies": val_class_acc_table
    })

    # Print epoch summary
    print(f"\nEpoch {epoch + 1}/{num_epochs}")
    print(f"Training   - Overall Accuracy: {train_overall_acc:.2f}%")
    print(f"Training   - Per Class Accuracies: {train_class_acc.cpu().numpy()}")
    print(f"Validation - Overall Accuracy: {val_overall_acc:.2f}%")
    print(f"Validation - Per Class Accuracies: {val_class_acc.cpu().numpy()}")

    return model


def log_test(self, step, per_class_acc, avg_loss, overall_acc):
        prefix = 'test/'
        
        # Log test metrics
        for i, acc in enumerate(per_class_acc):
            class_label = self.class_names.get(i, f'Class_{i}')
            self.writer.add_scalar(f'{prefix}Per Class Accuracy/{class_label}', acc, step)
        
        self.writer.add_scalar(f'{prefix}Average Loss', avg_loss, step)
        self.writer.add_scalar(f'{prefix}Overall Accuracy', overall_acc, step)

!tensorboard --logdir="/home/mejan/projects/intrusion/Network_Intrusion_detection/tensorboard_logs"